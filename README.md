# textclassifier

This is a Python application that utilizes the TextBlob library to analyze text content and determine its suitability for children. This application provides a user-friendly interface for users to upload text files and receive a safety evaluation based on the abusive probability.

Requirements
- Python 3.7 or above
- TextBlob library
- Streamlit library

Installation
1. Clone the repository:
```
git clone https://github.com/your-username/textclassifier.git
```
2. Navigate to the project directory:
```
cd textclassifier
```
3. Install the required dependencies:
```
pip install -r requirements.txt
```

Usage
1. Run the app.py file:
```
python app.py
```
The application will open in your browser.

2. Upload a text file using the file upload button.

3. The application will display the uploaded text along with a safety evaluation indicating whether it is non-abusive or abusive for children. .

4. Explore the textclassifer and analyze various text files for abusive language detection.

Acknowledgements
- TextBlob - The library used for abusive content analysis.
- Streamlit - The library used for building the user interface.

Feel free to contribute and make improvements to this project!
